---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---

I am a Research Fellow at the Simons Institute at UC Berkeley for the MPG program in fall 2024. Before that, I obtained my PhD in Mathematics at Georgia Institute of Technology, advised by Prof. Molei Tao.

# Research

I focus on the mathematical foundations of machine learning, especially from dynamical perspective. My research lies at the intersection of machine learning, optimization, sampling, (stochastic) dynamics, and computational math. Currently, I am interested in large language models and diffusion models.

My [CV](https://github.com/yzwangyuqing/yzwangyuqing.github.io/blob/cb3b9a04f5cdae189d896a2d2216db6d08920ef7/CV-4.pdf) and [Google Scholar](https://scholar.google.com/citations?user=c7Bi9RUAAAAJ&hl=en)

# Publications

Evaluating the design space of diffusion-based generative models\
**Yuqing Wang**, Ye He, Molei Tao\
preprint   [pdf](https://arxiv.org/pdf/2406.12839)

Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult\
**Yuqing Wang**, Zhenghao Xu, Tuo Zhao, Molei Tao\
Preprint (short version accepted in M3L, NeurIPS 2023 workshop)   [pdf (short version)](https://openreview.net/pdf?id=6O15A3h2yl) [pdf (long version)](https://arxiv.org/pdf/2310.17087.pdf)

Markov Chain Monte Carlo for Gaussian: A Linear Control Perspective\  
Bo Yuan, Jiaojiao Fan, **Yuqing Wang**, Molei Tao, Yongxin Chen  \
IEEE Control Systems Letters 2023   [pdf](https://ieeexplore.ieee.org/document/10147896)

Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport  \
Lingkai Kong, **Yuqing Wang**, Molei Tao  \
ICLR 2023   [pdf](https://arxiv.org/pdf/2205.14173.pdf)

Large Learning Rate Tames Homogeneity: Convergence and Balancing Effect  \
**Yuqing Wang**, Minshuo Chen, Tuo Zhao, Molei Tao  \
ICLR 2022   [pdf](https://arxiv.org/pdf/2110.03677.pdf)

Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks? — A Neural Tangent Kernel Perspective  \
Kaixuan Huang*, **Yuqing Wang***, Molei Tao, Tuo Zhao (*Equal contribution)  \
NeurIPS 2020   [pdf](https://arxiv.org/pdf/2002.06262.pdf)
