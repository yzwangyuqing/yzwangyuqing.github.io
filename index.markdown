---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---


<!-- <div class="wrapper">
    <div class="left-column">
        <img src="photo.jpg">
    </div>
    <div class="right-column">
            <p class="name">Yuqing Wang</p>
            <p>yq.wang@berkeley.edu</p>
            <p><a href="CV-4.pdf">CV</a></p> and <p><a href="https://scholar.google.com/citations?user=c7Bi9RUAAAAJ&hl=en"> Google Scholar</a> </p>
    </div>
</div> -->

<img src="photo.jpg" style="float: left;width:25%; margin-right:10%;"> 

## Yuqing Wang
yq.wang@berkeley.edu <br>
[CV](CV-4.pdf) and [Google Scholar](https://scholar.google.com/citations?user=c7Bi9RUAAAAJ&hl=en) <br>

<br clear="all" />

I am a Research Fellow at the Simons Institute at UC Berkeley for the MPG program in fall 2024. Before that, I obtained my PhD in Mathematics at Georgia Institute of Technology, advised by Prof. Molei Tao.


# Research

I focus on the mathematical foundations of machine learning, especially from dynamical perspective. My research lies at the intersection of machine learning, optimization, sampling, (stochastic) dynamics, and computational math, especially implicit biases of large learning rates. Currently, I am also interested in large language models and diffusion models.



# Publications

[Evaluating the design space of diffusion-based generative models](https://arxiv.org/pdf/2406.12839)\
**Yuqing Wang**, Ye He, Molei Tao\
NeurIPS 2024  

[Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult](https://arxiv.org/pdf/2310.17087.pdf)
\
**Yuqing Wang**, Zhenghao Xu, Tuo Zhao, Molei Tao\
preprint ([short version](https://openreview.net/pdf?id=6O15A3h2yl) accepted in M3L, NeurIPS 2023 workshop) 


[Markov Chain Monte Carlo for Gaussian: A Linear Control Perspective](https://ieeexplore.ieee.org/document/10147896)    
Bo Yuan, Jiaojiao Fan, **Yuqing Wang**, Molei Tao, Yongxin Chen  \
IEEE Control Systems Letters 2023   

[Momentum Stiefel Optimizer, with Applications to Suitably-Orthogonal Attention, and Optimal Transport](https://arxiv.org/pdf/2205.14173.pdf)  \
Lingkai Kong, **Yuqing Wang**, Molei Tao  \
ICLR 2023  

[Large Learning Rate Tames Homogeneity: Convergence and Balancing Effect](https://arxiv.org/pdf/2110.03677.pdf)  \
**Yuqing Wang**, Minshuo Chen, Tuo Zhao, Molei Tao  \
ICLR 2022  [video](https://recorder-v3.slideslive.com/?share=62680&s=8033b223-5733-4615-980e-6e7d6de0a914)

[Why Do Deep Residual Networks Generalize Better than Deep Feedforward Networks? — A Neural Tangent Kernel Perspective](https://arxiv.org/pdf/2002.06262.pdf)  \
Kaixuan Huang\*, **Yuqing Wang**\*, Molei Tao, Tuo Zhao (*Equal contribution)  \
NeurIPS 2020  [video](https://slideslive.com/38936904/why-do-deep-residual-networks-generalize-better-than-deep-feedforward-networks-a-neural-tangent-kernel-perspective)


# Teaching

TA in School of Mathematics, Georgia Institute of Technology:
- MATH 2552 Differential Equation, Fall 2018, Spring 2019, Fall 2019, Fall 2020, Spring 2021, Spring 2022, Spring 2023, Fall 2023
- MATH 2550 Introduction to Multivariable Calculus, Summer 2019, Summer 2024
- MATH 2551 Multivariable Calculus, Spring 2020
